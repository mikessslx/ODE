\section{Tutorial 3 - 10.31}

\subsection{Exercises on Picard Iterations}

\begin{xca}
Compute the Picard iterates for the initial-value problem
\[\frac{dy}{dt} = y, \ y(0) = 1\]
and observe that they converge to the solution \(y(t) = e^t, \ t \in \mathbb{R}\).
\end{xca}
\begin{proof}[Solution]
Remember that
\begin{align*}
y_0(t) &= y_0 = 1 \\
y_{n+1}(t) &= y_0 + \int_{t_0}^t f(s, y_n(s)) ds = 1 + \int_0^t y_n(s) ds
\end{align*}
(Here, \(f(t, y) = y, \ t_0=0, \ y_0=1\).)

\begin{itemize}
\item \(y_0(t) = 1\)
\item \(y_1(t) = 1 + \int_0^t ds = 1 + t\)
\item \(y_2(t) = 1 + \int_0^t (1+s) ds = 1 + t + \frac{t^2}{2}\)
\item \(y_3(t) = 1 + \int_0^t (1+s+\frac{s^2}{2}) ds = 1 + t + \frac{t^2}{2} + \frac{t^3}{2 \cdot 3}\)
\item \(\cdots\)
\item \(y_n(t) = 1 + t + \frac{t^2}{2} + \frac{t^3}{3!} + \cdots + \frac{t^n}{n!} \ ? \ (*)\)
\end{itemize}

We can prove that \(y_n\) is given by \((*)\) for \(n \ge 1\) by induction on \(n\). The result for \(n=1\) is direct. Assume that \(y_k(t)\) is given by \((*)\). We have,
\begin{align*}
y_{k+1}(t) &= 1 + \int_0^t y_k(s) ds = 1 + \int_0^t \sum_{j=0}^k \frac{s^j}{j!} ds = 1 + \sum_{j=0}^k \frac{s^{j+1}}{j!(j+1)} \\
&= 1 + \sum_{j=0}^k \frac{s^{j+1}}{(j+1)!} = 1 + \sum_{i=1}^{k+1} \frac{s^i}{i!} = \sum_{i=0}^{k+1} \frac{s^i}{i!}
\end{align*}

Notice that
\[\lim_{n \to \infty} y_n(t) = \sum_{n=0}^\infty \frac{t^n}{n!} = e^t = y(t)\]
for every \(t \in \mathbb{R}\).
\end{proof}

\begin{xca}
Compute the Picard iterates \(y_1(t)\) and \(y_2(t)\) for the initial-value problem
\[\begin{cases} \frac{dy}{dt} = 1 + y^3 \\ y(1) = 1 \end{cases}\]
\end{xca}
\begin{proof}[Solution]
Here, \(f(t, y) = 1 + y^3, \ t_0 = 1, \ y_0 = 1\).
\begin{itemize}
\item \(y_0(t) = 1\)
\item \(y_1(t) = 1 + \int_1^t (1+1) ds = 1 + 2(t-1) = 2t - 1\)
\item \(y_2(t) = 1 + \int_1^t (1 + (2s-1)^3) ds = 1 + \left[ s + \frac{(2s-1)^4}{8} \right]_1^t = \cdots = 2t^4 - 4t^3 + 3t^2\)
\end{itemize}
\end{proof}

\subsection{Exercises on Picard-Lindel\"of Theorem}

\begin{xca}
Show that the initial-value problem
\[\begin{cases} \frac{dy}{dt} = t^2 + e^{-y^2} \\ y(0) = 0 \end{cases}\]
has a unique solution near \(t=0\), and show the interval of definition.
\end{xca}
\begin{proof}[Solution]
The ODE is nonlinear, nonseparable. Also it's not exact, and it doesn't admit integrating factors depending on \(t\) or \(y\), only. We don't have tools to solve it!

We'll use the Picard-Lindel\"of theorem. Here \(f(t, y) = t^2 + e^{-y^2}, \ t_0 = 0, \ y_0 = 0\).

We need to check:
\begin{itemize}
\item \(f\) is continuous in \(R\).
\item \(\frac{\partial f}{\partial y}\) exists and is continuous in \(R\).
\end{itemize}

If this happens, we know that there exists a unique solution \(y(t)\) in \([0, \alpha]\) where \(\alpha = \min \{ a, \frac{b}{M} \}\) where \(M = \max_{(t,y) \in R} |f(t,y)|\).

\begin{itemize}
\item Since \(f(t, y) = t^2 + e^{-y^2}\) is cont. in \(\mathbb{R}^2\), so it's cont. in \(R\).
\item Also, \(\frac{\partial f}{\partial y}(t, y) = -2ye^{-y^2}\) is cont. in \(\mathbb{R}^2\), so it's cont. in \(R\).
\end{itemize}

There exists a unique solution \(y(t)\) in \([0, \alpha]\). Let's compute \(\alpha\). Let \(a=b=1\). Then,
\[M = \max |f(t,y)| = \max_{\substack{0 \le t \le 1 \\ -1 \le y \le 1}} (t^2 + e^{-y^2}) = 1 + 1 = 2\]

Thus, \(\alpha = \min \{ 1, \frac{1}{2} \} = \frac{1}{2}\).

The unique solution \(y(t)\) predicted by the theorem with \(a=b=1\) is defined in \([0, 1/2]\).
\end{proof}

\begin{xca}
Find the largest interval of definition of the unique solution to the problem
\[\frac{dy}{dt} = 1 + y^2, \ y(0) = 0,\]
that the Picard-Lindel\"of predicts.
\end{xca}
\begin{proof}[Solution]
Remember that we solved the problem and obtained that the unique solution is \(y(t) = \tan(t)\) for \(t \in \left(-\frac{\pi}{2}, \frac{\pi}{2}\right)\). Also notice that \(y(t)\) cannot be continued outside this interval as a continuous function.

Notice that \(\alpha = \min \left\{ a, \frac{b}{M} \right\}\) and \(M = \max_{-b \le y \le b} (1+y^2) = 1+b^2\). So, \(\alpha = \min \left\{ a, \frac{b}{1+b^2} \right\}\).
\end{proof}
